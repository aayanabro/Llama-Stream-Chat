# ü§ñ Groq-Powered Conversational AI Chatbot

A high-performance, persistent-memory chatbot built with **Streamlit**, **LangChain**, and **Groq Cloud**. This application leverages the speed of Llama-4 models to provide near-instantaneous conversational responses.

---

## ‚ú® Features

* **Ultra-Fast Inference**: Powered by Groq's LPU (Language Processing Unit) for industry-leading response times.
* **Conversation Memory**: Uses Streamlit Session State to maintain chat history, allowing the AI to remember previous context within a session.
* **Intuitive UI**: A clean, minimalist interface built with Streamlit.
* **Llama-4 Integration**: Utilizes the latest `llama-4-scout-17b` model for high-quality reasoning and assistance.

---

## üõ†Ô∏è Tech Stack

* **Frontend**: [Streamlit](https://streamlit.io/)
* **Orchestration**: [LangChain](https://www.langchain.com/)
* **LLM Provider**: [Groq Cloud](https://groq.com/)
* **Model**: Meta Llama 4 Scout (17B)
* **Environment Management**: `python-dotenv`

---

## ‚öôÔ∏è Setup & Installation

### 1. Clone the Repository
```bash
git clone [https://github.com/YOUR_USERNAME/YOUR_REPO_NAME.git](https://github.com/YOUR_USERNAME/YOUR_REPO_NAME.git)
cd YOUR_REPO_NAME
